{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Question number 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Lambda, MaxPooling1D, Conv1D, Flatten, LSTM\n",
    "import keras.backend as K\n",
    "from keras.models import Model,Sequential\n",
    "from keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 32)\n",
      "(500, 513, 32)\n",
      "200\n",
      "(200, 513, 45)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "with open('hw4_trs.pkl', 'rb') as f:\n",
    "    data_train = pickle.load(f)\n",
    "    \n",
    "    \n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "\n",
    "train_data=[]\n",
    "\n",
    "for i in range(500):\n",
    "    S=librosa.stft(data_train[i], n_fft=1024, hop_length=512)\n",
    "    train_data.append(S)\n",
    "print(S.shape)\n",
    "train_data=np.stack(train_data)\n",
    "print(train_data.shape)\n",
    "\n",
    "test_data=[]\n",
    "with open('hw4_tes.pkl', 'rb') as f1:\n",
    "    data_test = pickle.load(f1)\n",
    "\n",
    "    \n",
    "for i in range(200):\n",
    "    S=librosa.stft(data_test[i], n_fft=1024, hop_length=512)\n",
    "    test_data.append(S)\n",
    "print(len(test_data))\n",
    "\n",
    "test_data=np.stack(test_data)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 32, 513)\n"
     ]
    }
   ],
   "source": [
    "train_data=np.abs(train_data).transpose((0,2,1))\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 45, 513)\n"
     ]
    }
   ],
   "source": [
    "test_data=np.abs(test_data).transpose((0,2,1))\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Siamese Network\n",
    "## Reference was taken from keras Documentation and stack overflow\n",
    "# Define the tensors for the two input speech signals\n",
    "first_In = Input(shape=(None,513))\n",
    "second_In = Input(shape=(None,513))\n",
    "    \n",
    "# Convolutional Neural Network\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=2,activation='relu',strides=1, padding='same',input_shape=(None,513),kernel_initializer='he_normal'))\n",
    "model.add(MaxPooling1D(pool_size=2,strides=1, padding='valid'))\n",
    "model.add(Conv1D(filters=32, kernel_size=2,activation='relu',strides=1, padding='same',kernel_initializer='he_normal'))\n",
    "model.add(MaxPooling1D(pool_size=2,strides=1, padding='valid'))\n",
    "model.add(Conv1D(filters=32, kernel_size=3,activation='relu',strides=1, padding='same',kernel_initializer='he_normal'))\n",
    "model.add(MaxPooling1D(pool_size=2,strides=1, padding='valid'))\n",
    "model.add(Conv1D(filters=32, kernel_size=2, activation='relu', kernel_initializer='he_normal' ))\n",
    "model.add(LSTM(412))\n",
    "    \n",
    "# Generate the encodings (feature vectors) for the two speech signals\n",
    "encoded_1 = model(first_In)\n",
    "encoded_2 = model(second_In)\n",
    "    \n",
    " # Add a customized layer to compute the absolute difference between the encodings\n",
    "L1_layer = Lambda(lambda tensors:K.sum(tensors[0]*tensors[1],axis=-1,keepdims=True)) \n",
    "L1_dot = L1_layer([encoded_1, encoded_2])\n",
    "    \n",
    "# Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "prediction = Dense(1,activation='sigmoid')(L1_dot)\n",
    "    \n",
    "# Connect the inputs with the outputs\n",
    "siamese_net = Model(inputs=[first_In,second_In],outputs=prediction)\n",
    "    \n",
    "# compile the model\n",
    "siamese_net.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating batches of samples of train data\n",
    "from itertools import combinations\n",
    "import random\n",
    "import itertools\n",
    "def generator(train_data):\n",
    "    train_data=np.abs(train_data).transpose((0,2,1))\n",
    "    while True:\n",
    "        for i in range(0,510,10):\n",
    "            if i>=len(train_data)-10:\n",
    "                i=0\n",
    "            p=np.array(list(combinations(train_data[i:i+10],2)))\n",
    "            negative_1=list(itertools.product(train_data[i:i+10],train_data[i+10:500]))\n",
    "            negative_1=random.sample(negative_1,45)\n",
    "            negative_1=np.array(negative_1)\n",
    "            data_List=np.concatenate([p, negative_1])\n",
    "            label=[]\n",
    "            for i in range(45): \n",
    "                \n",
    "                label.append(1)\n",
    "            for i in range(45):\n",
    "                label.append(0)\n",
    "        \n",
    "            c = list(zip(data_List, label))\n",
    "            random.shuffle(c)\n",
    "            data_List, label = zip(*c)\n",
    "            data_List=np.array(data_List)\n",
    "            label=np.array(label)\n",
    "            data_List=data_List.transpose((1,0,2,3))\n",
    "\n",
    "            yield [data_List[0],data_List[1]], label[:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating batches of samples of test data\n",
    "from itertools import combinations\n",
    "import random\n",
    "import itertools\n",
    "def generator1(test_data):\n",
    "    test_data=np.abs(test_data).transpose((0,2,1))\n",
    "    while True:\n",
    "        for i in range(0,210,10):\n",
    "            if i>=len(test_data)-10:\n",
    "                i=0\n",
    "            p1=np.array(list(combinations(test_data[i:i+10],2)))\n",
    "            negative_2=list(itertools.product(test_data[i:i+10],test_data[i+10:200]))\n",
    "            negative_2=random.sample(negative_2,45)\n",
    "            negative_2=np.array(negative_2)\n",
    "            data_List1=np.concatenate([p1, negative_2])\n",
    "            label1=[]\n",
    "            for i in range(45):\n",
    "                label1.append(1)\n",
    "            for i in range(45):\n",
    "                 label1.append(0)\n",
    "            c1 = list(zip(data_List1, label1))\n",
    "            random.shuffle(c1)\n",
    "            data_List1, label1 = zip(*c1)\n",
    "            data_List1=np.array(data_List1)\n",
    "            label1=np.array(label1)\n",
    "            data_List1=data_List1.transpose((1,0,2,3))\n",
    "\n",
    "            yield [data_List1[0],data_List1[1]], label1[:90]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n",
      "50/50 [==============================] - 17s 343ms/step - loss: 0.8624 - acc: 0.5284\n",
      "Epoch 2/46\n",
      "50/50 [==============================] - 18s 354ms/step - loss: 0.6896 - acc: 0.5604\n",
      "Epoch 3/46\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a5cddaacbff5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Training model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msiamese_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m46\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "siamese_net.fit_generator(generator(train_data.transpose((0,2,1))),steps_per_epoch = len(train_data)/10, epochs = 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss and Accuracy\")\n",
    "print(siamese_net.evaluate_generator(generator1(test_data.transpose((0,2,1))),steps=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5487573377788066, 0.7566666692495346]\n",
      "[0.5264871641993523, 0.7633333295583725]\n",
      "[0.5284012071788311, 0.7649999976158142]\n",
      "[0.5365496590733528, 0.7666666626930236]\n",
      "[0.5503831684589386, 0.7572222203016281]\n",
      "[0.5395398572087288, 0.7616666615009308]\n",
      "[0.5279035538434982, 0.7616666674613952]\n",
      "[0.5462457910180092, 0.7594444364309311]\n",
      "[0.5402844786643982, 0.7572222232818604]\n",
      "[0.5592226281762123, 0.7588888943195343]\n",
      "[0.5583599336445332, 0.7533333331346512]\n",
      "[0.5379051901400089, 0.7594444453716278]\n",
      "[0.5240912184119224, 0.7677777737379075]\n",
      "[0.49870396628975866, 0.774444442987442]\n",
      "[0.5237208358943463, 0.7688888847827912]\n",
      "[0.5572159722447395, 0.7538888841867447]\n",
      "[0.5554444551467895, 0.7544444501399994]\n",
      "[0.510335161536932, 0.778333330154419]\n",
      "[0.548049197345972, 0.7516666650772095]\n",
      "[0.5270741648972035, 0.7644444465637207]\n",
      "[0.5424028195440769, 0.7588888883590699]\n",
      "[0.5603345267474651, 0.7527777791023255]\n",
      "[0.5477474495768547, 0.7577777743339539]\n",
      "[0.5437770634889603, 0.7655555516481399]\n",
      "[0.5425609283149242, 0.7616666615009308]\n",
      "[0.5489982940256596, 0.7555555611848831]\n",
      "[0.5229904770851135, 0.7616666734218598]\n",
      "[0.5434062570333481, 0.7583333343267441]\n",
      "[0.5633561201393604, 0.7477777808904648]\n",
      "[0.5464126095175743, 0.7599999994039536]\n",
      "[0.5323002979159355, 0.7722222179174423]\n",
      "[0.5889124266803265, 0.7455555498600006]\n",
      "[0.5267936289310455, 0.7727777749300003]\n",
      "[0.5341635949909687, 0.7599999964237213]\n",
      "[0.524632704257965, 0.7655555516481399]\n",
      "[0.5545668415725231, 0.7566666662693023]\n",
      "[0.5535924196243286, 0.7516666650772095]\n",
      "[0.5103137783706189, 0.7738888919353485]\n",
      "[0.5309755794703961, 0.7594444423913955]\n",
      "[0.5456815235316753, 0.7550000041723252]\n",
      "[0.5544004246592522, 0.7533333331346512]\n",
      "[0.5204817518591881, 0.7672222197055817]\n",
      "[0.5576804257929325, 0.7561111092567444]\n",
      "[0.5293824836611748, 0.7638888895511627]\n",
      "[0.5378466106951236, 0.7638888865709305]\n",
      "[0.5086584888398648, 0.7716666698455811]\n",
      "[0.5263743601739407, 0.7672222256660461]\n",
      "[0.5348467491567135, 0.7672222226858139]\n",
      "[0.5317518062889576, 0.761666664481163]\n",
      "[0.5557847499847413, 0.761666664481163]\n",
      "[0.5154075480997562, 0.7644444406032562]\n",
      "[0.5721747256815434, 0.7433333307504654]\n",
      "[0.5598853804171086, 0.7555555552244186]\n",
      "[0.5164165951311588, 0.7611111134290696]\n",
      "[0.5400761231780052, 0.7711111068725586]\n",
      "[0.5376446396112442, 0.7572222232818604]\n",
      "[0.5331704609096051, 0.7638888895511627]\n",
      "[0.5126706823706627, 0.7672222167253494]\n",
      "[0.5360409192740917, 0.757777777314186]\n",
      "[0.5396530225872993, 0.7633333384990693]\n",
      "[0.5902496002614498, 0.7316666722297669]\n",
      "[0.5439246669411659, 0.7611111134290696]\n",
      "[0.5585273951292038, 0.7544444411993027]\n",
      "[0.5477426670491695, 0.7522222191095352]\n",
      "[0.5418524950742721, 0.7605555504560471]\n",
      "[0.5193272188305855, 0.7738888800144196]\n",
      "[0.5490574173629283, 0.7555555522441864]\n",
      "[0.5275314636528492, 0.7655555576086044]\n",
      "[0.5217061199247837, 0.7816666662693024]\n",
      "[0.5611124128103256, 0.7549999982118607]\n",
      "[0.5371282652020455, 0.7577777743339539]\n",
      "[0.5171697534620762, 0.7672222226858139]\n",
      "[0.5314351864159107, 0.7688888847827912]\n",
      "[0.5255690231919289, 0.7699999928474426]\n",
      "[0.5383777610957623, 0.7566666692495346]\n",
      "[0.5413818933069706, 0.7661111116409302]\n",
      "[0.5305371508002281, 0.7672222256660461]\n",
      "[0.5472073756158352, 0.7583333313465118]\n",
      "[0.5451535232365131, 0.7611111104488373]\n",
      "[0.5612278252840042, 0.7561111092567444]\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(siamese_net.evaluate_generator(generator1(test_data.transpose((0,2,1))),steps=20))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
